---
id: 1
icon: "🤖"
title: "LLM이 뭐예요?"
description: "사람처럼 글을 읽고 쓰는 인공지능 이야기"
---

## 1️⃣ LLM은 "다음 말을 잘 맞히는 AI"예요

LLM(Large Language Model)은 엄청나게 많은 글을 읽고, "다음에 올 말이 뭘까?"를 잘 맞히도록 훈련된 AI입니다.

예시를 들어보겠습니다.

> "오늘 점심으로 나는 김치찌개를 ___"
> 

이 문장을 보면 LLM은 이렇게 생각합니다.

- "먹었다"일 확률이 높겠네🤔
- "주문했다"도 괜찮은데?
- "싫어했다"...? 이건 좀 어색한데?

다음에 올 단어를 확률적으로 고르는 것, 이게 LLM의 핵심 원리입니다.

---

## 2️⃣ 핵심 원리: 다음 단어 맞히기

LLM은 사실 문장을 완벽하게 이해한다기보다는, 지금까지 나온 단어들을 보고 다음 단어를 계산합니다.
이때 한 단어씩, 순서대로 만들어 나갑니다.

이 방식을 autoregressive generation(자기회귀적 생성)이라고 부릅니다.

### 한 단어씩 만들어지는 과정

예를 들어, LLM이 이런 문장을 만들고 싶다고 해봅시다.

> "나는 오늘 커피를 마셨다"
> 

LLM은 처음부터 이 문장을 알고 있는 게 아닙니다.

실제로는 이렇게 작동합니다 👇

![llm설명_그림.png](attachment:25e1a637-027f-44ea-9f3a-48281c6192f9:llm설명_그림.png)

### 정리하면,

앞에서 만든 단어들을 다시 입력으로 사용해서,

👉 또 다음 단어를 예측하고 👉 또 그 결과를 이용하고 👉 또 다음 단어를 예측합니다.

이걸 바로 autoregressive(자기회귀적 생성)라고 부릅니다.

→ "자기가 만든 결과를 다시 보고, 그다음을 예측한다"는 뜻입니다.

---

### 그래서 LLM은 이런 특징이 있습니다.

✔ 글을 왼쪽에서 오른쪽으로 차근차근 만듦
✔ 앞에 쓴 내용에 강하게 영향을 받음
✔ 중간에 이상한 단어가 나오면, 그 뒤 문장도 안 좋은 영향을 받음

→ 그래서 질문을 어떻게 시작하느냐가 중요하고, 초반 문맥이 특히 중요함

---

## 3️⃣ 그럼 LLM은 문장을 어떻게 "선택"할까?

아까 봤던 예시를 다시 보겠습니다.

> "나는 오늘 커피를 마셨다. 그래서 지금 너무 ___"
> 

LLM은 이 빈칸에서 단 하나의 정답을 고르는 게 아니라, 후보 단어들의 확률 분포를 만듭니다.

---

## 4️⃣ LLM은 어떻게 이렇게 똑똑해졌을까?

비밀은 의외로 단순합니다.

1. 인터넷에 있는 엄청난 양의 글을 읽는다
2. "다음 단어 맞히기"를 수십억 번 반복한다
3. 틀리면 조금씩 고친다
4. 점점 더 잘 맞히게 된다

이 과정을 "훈련(training)"이라고 부릅니다.

---

`미니 실습`

그런데 여기서 한 가지 문제가 있습니다. LLM은 ‘다음 단어 맞히기’는 잘하지만, 우리가 원하는 방식으로 답을 내게 만들려면 질문을 잘 던져야 합니다. 그 방법이 바로 prompting입니다. (다음에서 계속)